# Thread 
- [쓰레드]()
- 쓰레드 상태, 데몬 쓰레드, 버추얼 쓰레드, Java버전별 쓰레드 구현 방식, 동기화 매커니즘
<br>

### **쓰레드 상태 (Thread States)**
- 로그램 실행 중 스레드가 어떤 작업을 하고 있는지 나타내는 중요한 정보.
1. **NEW (새로운 상태)** : 준비중 / 쓰레드가 생성되었지만 아직 start()가 호출되지 않은 상태.
2. **RUNNABLE(실행 가능 상태)** : 대기 중 또는 실행 중 / **start()**를 호출해서 실행 준비가 된 상태.
3. **BLOCKED(대기 상태)**: 잠시 기다리는 중 / 어떤 자원을 사용하려고 했는데 다른 쓰레드가 사용 중이라 잠시 멈춘 상태. (자원을 사용할 수 있게 되면 다시 RUNNABLE 상태로 돌아감.)
4. **WAITING(무기한 대기 상태)**: 다른 쓰레드의 명시적 신호를 기다리는 상태. 다른 쓰레드가 notify() 또는 notifyAll()을 호출해야 깨어남.
5. **TIMED_WAITING(시간 제한 대기 상태)**: 정해진 시간 동안 기다리는 중 / sleep(), join(time), wait(time) 등이 호출될 때 발생.
6. **TERMINATED(종료 상태)**: 쓰레드의 작업이 모두 끝나고 더 이상 실행되지 않는 상태. 한 번 종료된 쓰레드는 다시 시작할 수 없음.

### 쓰레드 상태를 왜 알아야 하는가
1. 데드락: 여러 스레드가 서로 락을 획득하기 위해 무한히 기다리는 상태를 확인하고 해결할 수 있음.
2. 리빙락: 스레드들이 서로 양보하면서 진행되지 않는 상태를 확인하고 해결할 수 있음.
3. 무한 루프: 특정 스레드가 무한 루프에 빠져 있는지 확인하고 원인을 파악할 수 있음.
4. 자원 부족: 특정 자원이 부족하여 스레드가 블록되어 있는지 확인할 수 있음.
5. 병목 현상: 특정 스레드가 다른 스레드의 작업을 방해하거나 시스템 자원을 과도하게 사용하는지 확인하여 성능을 향상시킬 수 있음.
6. 스케줄링 문제: 스레드 스케줄링이 적절하게 이루어지지 않아 성능이 저하되는 경우, 스레드 상태를 분석하여 문제를 해결할 수 있음.
7. 예외 발생: 어떤 스레드에서 예외가 발생했는지, 예외 발생 시 스레드의 상태는 어떠했는지 확인하여 문제를 해결할 수 있습있음니다.

#### (+) 쓰레드 덤프
- 쓰레드 덤프는 실행 중인 프로그램의 모든 스레드에 대한 정보를 캡처한 것.
- 스레드 덤프에는 각 스레드의 상태, 스택 트레이스, 실행 중인 메소드, 보유한 락 등 다양한 정보가 포함되어 있음.

<br>

### 데몬 쓰레드(Daemon Thread)
- **모든 일반 쓰레드 종료 시 자동 종료 (일반 스레드는 스스로 종료되거나, JVM이 종료될 때까지 실행)**
- 백그라운드에서 실행되는 보조적인 작업을 수행하는 쓰레드 → 우선순위가 낮음.
- 데몬 쓰레드는 프로그램 종료 시 강제로 종료되므로, **중요한 작업**에는 적합하지 않음.
- ex. 로그기록, **가비지 컬렉터(Garbage Collector)**, **JVM 메인 쓰레드의 보조 작업**

### 데몬 쓰레드 설정 방법
- **데몬 쓰레드로 설정하려면** Thread 클래스의 setDaemon(true) 메서드를 호출
- **쓰레드를 시작하기 전에만** 가능하며, 시작 후 변경하려고 하면 IllegalThreadStateException이 발생

```java
public class DaemonExample {
    public static void main(String[] args) {
        Thread daemonThread = new Thread(() -> {
            while (true) {
                System.out.println("Daemon thread is running...");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    System.out.println("Daemon thread interrupted.");
                    break;
                }
            }
        });

        // 데몬 쓰레드 설정
        daemonThread.setDaemon(true);
        daemonThread.start();

        // 메인 쓰레드 종료
        System.out.println("Main thread is ending.");
    }
}
```

<br>

### 스레드 풀(Thread Pool)
- 미리 생성된 스레드 객체의 모음
- 작업 요청이 들어오면 스레드를 생성하지 않고 미리 만들어진 스레드를 재사용하는 구조
- 이를 통해 스레드 생성 및 소멸에 드는 비용을 줄이고, 시스템 성능을 향상시킬 수 있음.

#### 스레드 풀을 사용하는 이유
1.	효율적인 리소스 관리 : 스레드 생성 및 소멸의 반복을 방지하여 시스템 자원 절약, 스레드 과도한 요청 제한.
2.	작업 큐 관리 : 작업 요청이 많을 때 대기열(Queue)에 쌓아 두고 스레드가 여유가 생기면 처리.
3.	성능 향상 : 대량의 작업 처리에서 응답성과 처리 속도가 향상
4.	스레드 개수 제한 : 시스템의 병렬 처리 능력을 초과하지 않도록 스레드 수를 제어할 수 있음.

#### 스레드 풀 사용 시 주의 사항
- **스레드 개수 설정:** 스레드 개수를 적절하게 설정해야 함. 너무 적으면 작업 처리 속도가 느려지고, 너무 많으면 시스템 자원을 낭비할 수 있음.
- **작업 큐 크기:** 작업 큐의 크기를 적절하게 설정. 큐가 가득 차면 새로운 작업이 거부될 수 있음.
- **스레드 종료:** 스레드 풀을 종료할 때는 모든 작업이 완료될 때까지 기다리거나 강제로 종료해야 함.


```java
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class ThreadPoolExample {
    public static void main(String[] args 1 ) {
        // 스레드 풀 생성 (최대 5개의 스레드)
        ExecutorService executor = Executors.newFixedThreadPool(5);

        // 작업 제출
        for (int i = 0; i < 10; i++) {
            executor.submit(() -> {
                System.out.println("Task executed by " + Thread.currentThread().getName());
            });
        }

        // 스레드 풀 종료
        executor.shutdown();
    }
}
```

#### 스레드 풀 크기 결정 공식 (기본 규칙)
- 공식 : 최적 스레드 수 = CPU 코어 수 × (1 + 작업 대기 시간 ÷ 작업 처리 시간)
- 설명 :
  - CPU 코어 수: 사용할 수 있는 물리적/논리적 CPU 코어의 개수.
  - 작업 처리 시간 (CPU Time): CPU가 작업을 처리하는 데 걸리는 시간.
  - 작업 대기 시간 (Wait Time): 작업이 I/O(네트워크, 파일, 데이터베이스 등) 작업 때문에 대기하는 시간.
- 예시
  - CPU가 4개이고, 작업 대기 시간이 처리 시간의 2배라면:
  -> 스레드 풀 크기 = 4 \times (1 + \frac{2}{1}) = 4 \times 3 = 12

#### 작업 유형별 스레드 풀 크기 지침
- CPU 집약적 작업 (계산, 데이터 처리 등 CPU를 많이 사용하는 작업.)
  - 스레드 수 ≈ CPU 코어 수 : CPU가 더 많은 스레드를 효율적으로 처리할 수 없기 때문에, 코어 수와 동일하게 설정
- I/O 집약적 작업 (파일 읽기/쓰기, 네트워크 요청, 데이터베이스 쿼리 등 대기 시간이 많은 작업.)
- 스레드 수 ≈ CPU 코어 수 × 2~4 : 대기 시간이 많아 CPU가 쉬는 시간이 길기 때문에 더 많은 스레드가 효율적

#### 스레드 풀 설계 시 고려 사항
1.	작업 수와 실행 시간
    - 작업이 짧고 많다면, 상대적으로 큰 스레드 풀이 적합.
    - 작업이 길다면 스레드 풀 크기를 작게 설정.
2.	시스템 리소스 제한
    - CPU와 메모리 자원이 제한적이므로 너무 많은 스레드를 생성하면 오히려 성능이 떨어질 수 있음.
3.	작업 우선순위
    - 낮은 우선순위 작업은 대기열에 오래 두고, 높은 우선순위 작업은 빠르게 처리하도록 설계.
4.	ThreadFactory 사용
    - 스레드 이름을 명확히 설정하여 디버깅을 용이하게 함.
5.	스레드 풀 종료 처리
    - 작업이 끝난 후 스레드 풀이 적절히 종료되도록 설정 (shutdown() 호출).

## Run() VS Start()
### Run()
- 현재 호출한 스레드에서 실행 -> 새로운 쓰레스 생성 X
- 일반 메서드 호출과 동일하게 작동하고, 비동기(병렬적)실행이 불가능함. 
- 현재 호출한 스레드의 Stack영역에서 실행.

### Start()
- 새로운 쓰레드드의 Stack영역을 생성하고 JVM이 관리하는 스레드 스케줄링에 의해 run() 메서드를 호출하도록 함. (실행 중 생성된 객체는 힙 영역에 저장되며 다른 스레드와 공유가능.)
- 쓰레드의 비동기적/병렬적 실행이 가능함

<br>
<br>

## Java 버전별 스레드 처리 매커니즘 (구현/처리 방식)
### Java 5 이전 : Runnable과 Thread
- **Runnable 인터페이스:** 스레드가 실행할 작업을 정의하는 가장 기본적인 방법
- **Thread 클래스:** Runnable 인터페이스를 구현한 객체를 이용하여 스레드를 생성하고 시작
- 즉, Thread 클래스는 runnable 인터페이스를 구현한거라서 어떤 것을 사용하든지 크게 다르지 않음. 그러나, 쓰레드 클래스가 다른 클래스를 확장할 필요가 있다면 runnable 인터페이스를 구현하고 그렇지 않으면 thread클래스를 상속받으면 됨 (인터페이스는 다중 상속이 가능하고, 클래스는 다중 상속이 불가능하기 때문)
- **장점** : 간단하고 직관적인 스레드 생성 및 관리
- **단점** : 작업 결과를 반환하기 어렵고, 스레드 풀을 사용하기 어려움
- 간단한 스레드 처리가 필요할 때, 작업 결과를 반환할 필요가 없을 때


### Java 5: Callable, Future, Executor, ExecutorService, Executors
- **Callable 인터페이스**
    - **Runnable 인터페이스**의 확장된 개념
    - Runnable은 단순히 작업을 실행하는 반면, Callable은 작업 결과를 반환이 가능하며, 예외 처리가 가능함. (call()메서드 활용)
    - 단독으로 사용하기 어렵고, 주로 ExecutorService와 함께 사용됨.
- **Future 인터페이스**
    - 비동기 작업의 결과를 나타내는 객체
    - 작업이 완료되었는지 확인하거나 결과를 가져오는 기능을 제공 (get()메서드 활용))
    - '미래의 값을 가져온다' : Future는 비동기 작업의 결과를 나중에 가져올 수 있도록 도와줌 -> 결과는 작업이 완료된 “미래 시점”에 사용할 수 있음으로 이를 “미래의 값”이라고 표현함.
- **Executor 인터페이스**
    - Executor는 작업 실행의 기본 인터페이스로, 스레드 생성 및 관리의 추상화를 제공
    - 기존의 직접적인 스레드 생성 방식은 코드가 복잡하고 비효율적 -> Executor는 이 문제를 해결하기 위해 설계됨
    - 단순한 인터페이스로 작업 상태 관리 등의 고급 기능을 지원하지 않음. 이를 위해 ExecutorService가 필요함.
- **ExecutorService 인터페이스**
    - **Executor 인터페이스를 확장**하여 더 많은 기능을 제공 → 고급의 쓰레드 관리 기능
    - 스레드 풀 관리와 작업 상태 추적, 비동기 작업 결과 처리를 지원
- **Executors 클래스**
    - **ExecutorService의 구현체**를 제공하는 유틸리티 클래스.
    - **newFixedThreadPool(), newCachedThreadPool() 등** 다양한 종류의 스레드 풀을 생성하는 메소드를 제공


### Java 7 : Fork/Join 프레임워크 (분할/결합)
- 큰 작업을 작은 작업으로 분할하여 병렬 처리하고, 결과를 합치는 분할 정복(Divide and Conquer) 방식의 프레임워크
    - **Fork (분할):** 큰 작업을 더 작은 서브태스크로 재귀적으로 분할하는 과정 서브태스크가 충분히 작아질 때까지 분할을 계속함.
    - **Join (결합):** 분할된 서브태스크의 결과를 합쳐 최종 결과를 얻는 과정.

- **장점:**
    - 스레드 풀이 자동으로 관리됨
    - 분할 정복 알고리즘에 적합한 문제를 효율적으로 병렬 처리할 수 있음
- **단점:**
    - 구현이 복잡할 수 있음
    - 모든 문제에 적용하기에는 오버헤드가 발생할 수 있음
- **사용 시기:**
    - 대규모 데이터 처리, 수치 계산 등 분할 정복 알고리즘에 적합한 문제
    - 작업이 서로 독립적이고, 반복적으로 분할 가능한 경우

```java
import java.util.concurrent.ForkJoinPool;
import java.util.concurrent.RecursiveTask;

class CalculateSum extends RecursiveTask<Long> {
    // ...
}

public class Main {
    public static void main(String[] args) {
        ForkJoinPool pool = new ForkJoinPool();
        CalculateSum task = new CalculateSum(/* ... */);
        long result = pool.invoke(task);
    }
}
```

### Java 8: CompletableFuture 클래스

- 비동기/병렬적 실행가능.
- 콜백 메서드 : 결과가 도착했을 때 콜백이 가능
- 예외처리 가능 : 작업 중 발생한 예외를 처리하거나 예외 상황에 따른 대체 값 설정 가능.
- 지원하는 메서드들이 많아서 보통 이걸 많이 씀.
- **단점:**
    - 디버깅 어려움 : 비동기 작업 체이닝이나 병렬 실행이 많아질수록 디버깅이 어려워짐
    - 코드 복잡성 증가 : 비동기 작업의 체이닝이 길어지면 코드가 난해해 질수 있음.
    - 복잡한 흐름 제어의 한계 : 단순한 비동기 작업에는 적합하지만 매우 복잡한 상태 관리나 작업 간의 의존성이 높은 경우는 코드 관리가 어려움.
- **사용 시기:**
    - 단순한 비동기 작업 : 네트워크 호출, 데이터베이스 쿼리, 파일 I/O작업
    - 여러 작업의 병렬 실행 및 병합해야 할 때 : 여러 API 호출의 결과를 합쳐서 반환하는 서비스

```java
import java.util.concurrent.CompletableFuture;

public class Main {
    public static void main(String[] args) {
        CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {
            // 비동기 작업
            return "Hello";
        });

        future.thenAccept(System.out::println);
    }
}
```

### Java 9: Flow
- **자바 Flow**는 특정한 키워드나 구문을 가리키는 용어라기보다는, **데이터를 처리하고 변환하는 과정을 추상화하여 표현하는 개념**
- 즉, 데이터가 생성되고 변형되어 최종 결과물로 이어지는 일련의 과정을 하나의 흐름(Flow)
- 스레드와 직접적으로 관련되어 있지는 않지만, 스레드를 효율적으로 활용하여 비동기 처리, 백프레셔, 병렬 처리 등을 지원함.

### Flow 활용
- **비동기 처리:** Flow는 비동기적인 데이터 처리를 위한 추상화 레이어를 제공.
- **백프레셔:** Flow는 백프레셔 메커니즘을 통해 데이터 처리 속도를 조절, 과도한 데이터 생성으로 인한 시스템 과부하를 방지
- **병렬 처리:** Flow는 여러 개의 데이터를 병렬적으로 처리하는 것을 지원

### Flow를 제공하는 대표적인 라이브러리
- **RxJava를 이용한 네트워크 통신:** RxJava를 사용하여 HTTP 요청을 비동기적으로 보내고, 결과를 받아 처리하는 과정에서 스레드 풀을 활용하여 병렬 처리를 수행
- **Project Reactor를 이용한 서버 사이드 이벤트 스트림:** Project Reactor를 사용하여 서버 사이드 이벤트 스트림을 구현하고, 다수의 클라이언트에게 실시간으로 데이터를 전달하는 과정에서 비동기 처리와 백프레셔를 적용
- **Kotlin Coroutines를 이용한 비동기 파일 처리:** Kotlin Coroutines를 사용하여 대용량 파일을 비동기적으로 읽고 처리하는 과정에서 스레드를 효율적으로 활용

#### 코루틴(Coroutines)
- 함수의 실행을 일시 중단하고 나중에 다시 이어서 실행할 수 있는 기능을 제공하는 프로그래밍 언어의 한 구성 요소
- 일반적인 함수 호출과 달리, 코루틴은 실행 중에 중단되었다가 다시 시작될 수 있음.
- 이러한 특징을 통해 비동기 프로그래밍을 더욱 직관적이고 효율적으로 구현할 수 있게 해줌.
- 자바에서의 코루틴은 Flow API를 통해 제공됨. Flow는 코틀린에서 처음 도입되어 자바로 확장된 비동기 데이터 스트림을 위한 추상화 레이어.
- 일반적으로 비선점형 방식으로 스케줄링 됨. 즉, 코루틴이 실행을 시작하면 다른 코루틴이 끼어들어 실행을 중단시키지 않고, 스스로 suspend 함수를 호출하여 실행을 일시 중단해야 해야 함.

## 버추얼 스레드(Virtual Thread)
- 기존의 운영체제 스레드와는 다르게, **JVM(Java Virtual Machine) 내에서 관리되는 경량 스레드**
- 마치 가상 머신에서 실행되는 가상 머신처럼, JVM 내에서 또 다른 스레드를 가상으로 만들어 사용하는 것

### 버추얼 스레드를 사용하는 이유
- **더 많은 스레드 생성:** 기존 스레드는 운영체제의 자원을 많이 차지하기 때문에 생성할 수 있는 스레드의 수가 제한적임. 하지만 버추얼 스레드는 메모리 사용량이 적고, JVM에서 효율적으로 관리되어 수천, 수만 개의 스레드를 생성하고 관리할 수 있음.
- **더 나은 성능:** 버추얼 스레드는 컨텍스트 스위칭 비용이 적고, I/O 작업 시 효율적으로 스케줄링되어 기존 스레드보다 더 나은 성능을 제공 특히 I/O 바운드 작업이 많은 애플리케이션에서 효과적
- **개발 편의성:** 기존 스레드와 비슷한 방식으로 사용할 수 있어 개발자가 쉽게 학습하고 사용할 수 있음.

### 버추얼 스레드의 장점
- **높은 처리량:** 많은 수의 동시 작업을 처리할 수 있음.
- **낮은 메모리 사용량:** 기존 스레드보다 적은 메모리를 사용함.
- **높은 성능:** 컨텍스트 스위칭 비용이 적어 성능이 우수함
- **개발 편의성:** 기존 스레드와 유사한 API를 사용함.

### 버추얼 스레드의 단점
- **새로운 기술:** 아직 모든 개발 환경에서 지원되지 않으며, 버그가 있을 수 있음.
- **복잡성:** 기존 스레드보다 복잡한 내부 구조를 가지고 있어, 깊이 이해하기 위해서는 추가적인 학습이 필요할 수 있음.

### 버추얼 스레드의 활용 사례
- **I/O 바운드 애플리케이션:** 웹 서버, 데이터베이스 연결 등 I/O 작업이 많은 애플리케이션에서 효과적.
- **대규모 데이터 처리:** 많은 양의 데이터를 병렬 처리해야 하는 경우에 유용.
- **반응형 시스템:** 사용자 요청에 빠르게 응답해야 하는 시스템에 적합.


### 임계 영역(Critical Section)이란?
-여러 스레드가 동시에 접근하면 안 되는 코드 블록을 의미.
- 이 영역에서는 공유 데이터에 대한 읽기 또는 쓰기 작업이 이루어지는데, 여러 스레드가 동시에 접근하면 예측할 수 없는 결과가 발생할 수 있음.

### 락(Lock)이란?
- 락은 임계 영역에 대한 접근을 제어하는 메커니즘.
- 한 번에 하나의 스레드만 임계 영역에 들어갈 수 있도록 락을 걸어 다른 스레드의 접근을 막음.
- 락을 획득한 스레드만 임계 영역에 들어가 작업을 수행하고, 작업이 끝나면 락을 해제하여 다른 스레드가 접근할 수 있도록 함.

### 락의 종류
1. 스핀락(Spinlock)
- 특징: 락을 획득하지 못한 스레드가 busy-waiting 상태로 계속해서 락을 획득하려고 시도함.
- 장점: 락을 획득하는 데 걸리는 시간이 짧음.
- 단점: CPU 자원을 많이 소모하며, 락을 획득하는 데 오랜 시간이 걸릴 경우 시스템 전체 성능이 저하될 수 있음.
- 사용 시나리오: 락을 획득하는 데 걸리는 시간이 매우 짧고, CPU 자원이 충분한 경우에 적합함.

2. 뮤텍스(Mutex)
- 특징: 한 번에 하나의 스레드만 락을 획득할 수 있으며, 락을 획득하지 못한 스레드는 블록 상태로 전환
- 장점: 스핀락에 비해 CPU 자원을 적게 소모함
- 단점: 스레드가 블록 상태로 전환되기 때문에 스케줄링 오버헤드가 발생할 수 있음
- 사용 시나리오: 일반적인 상황에서 가장 많이 사용되는 락.

3. 세마포어(Semaphore)
- 특징: 락을 일반화한 개념으로, 동시에 접근할 수 있는 자원의 개수를 제한.
- 장점: 뮤텍스와 비슷하지만, 더 유연하게 자원 접근을 제어할 수 있음
- 단점: 구현이 복잡하고, 오용하면 데드락이 발생할 수 있음
- 사용 시나리오: 여러 개의 스레드가 동시에 제한된 자원에 접근해야 할 때 사용함.


## 분산 락(Distributed Lock)이란?
- 분산 락은 여러 서버 또는 프로세스에서 동일한 자원에 접근할 때, 데이터의 일관성을 유지하기 위해 사용되는 동기화 메커니즘
- 단일 서버 환경에서 사용하는 일반적인 락과 달리, 분산 락은 여러 개의 독립적인 시스템에서 동작해야 하기 때문에 더 복잡한 문제들을 고려해야 함.

### 왜 분산 락이 필요할까요?
- 분산 시스템: 마이크로서비스 아키텍처, 클라우드 환경 등 분산된 시스템에서는 여러 서버가 공유된 데이터에 접근해야 하는 경우가 많음.
- 데이터 일관성: 여러 서버에서 동시에 데이터를 수정할 때 데이터의 일관성을 유지해야 해야함.
- 경쟁 조건 방지: 여러 서버가 동시에 같은 자원에 접근하여 예기치 못한 결과를 초래하는 경쟁 조건을 방지 해야함.
- 분산 락의 예시
  - 캐시 시스템: 여러 서버에서 공유하는 캐시 데이터를 업데이트할 때, 동시에 여러 서버가 업데이트를 시도하지 않도록 분산 락을 사용
  - 데이터베이스: 여러 트랜잭션이 동시에 데이터베이스를 수정할 때, 데이터의 일관성을 유지하기 위해 분산 락을 사용.
  - 분산 파일 시스템: 여러 클라이언트가 동시에 파일을 수정할 때, 파일 시스템의 일관성을 유지하기 위해 분산 락을 사용.

#### 분산 락 구현 방식
- 데이터베이스 기반: 데이터베이스의 트랜잭션 기능을 이용하여 락을 구현.
- Redis 기반: Redis의 SETNX 명령어를 이용하여 락을 구현.
- ZooKeeper 기반: ZooKeeper의 znode를 이용하여 분산 락을 구현.
- etcd 기반: etcd의 KV 스토어를 이용하여 분산 락을 구현.

#### 분산 락 구현 시 고려 사항
- 성능: 분산 락은 시스템의 성능에 영향을 미칠 수 있으므로, 성능을 고려하여 적절한 알고리즘을 선택해야 함.
- 가용성: 분산 시스템의 특성상, 시스템의 일부가 장애가 발생하더라도 락이 정상적으로 동작해야 함.
- 데드락: 여러 프로세스가 서로 락을 기다리면서 영원히 블록되는 데드락이 발생하지 않도록 주의해야 함.

#### 분산 락의 어려움
- 네트워크 지연: 분산 환경에서는 네트워크 지연으로 인해 락 획득 및 해제에 시간이 오래 걸릴 수 있음.
- 시스템 장애: 시스템 장애로 인해 락이 해제되지 않고 영구히 유지될 수 있음.
- 구현 복잡도: 분산 락을 구현하고 관리하는 것은 단일 시스템의 락을 구현하는 것보다 훨씬 복잡함.

## 쓰레드를 사용하면서 발생할 수 있는 문제
1. 경쟁 조건 (Race Condition)
- 여러 스레드가 공유 데이터에 동시에 접근하여 예측할 수 없는 결과가 발생하는 현상
- ex. 두 개의 스레드가 동시에 같은 계좌 잔액을 증가시키려 할 때, 각 스레드가 잔액을 읽고 증가시키는 사이에 다른 스레드가 값을 변경하여 예상치 못한 결과가 나올 수 있음.
 - 해결 방법
    - 임계 영역 보호: synchronized 키워드, Lock 인터페이스 등을 사용하여 한 번에 하나의 스레드만 공유 데이터에 접근하도록 제한
    - 원자성 연산: AtomicInteger, AtomicLong 등의 클래스를 사용하여 단일 명령어로 값을 읽고 쓰는 연산을 수행

2. 데드락 (Deadlock)
- 두 개 이상의 스레드가 서로 상대방이 획득한 자원을 기다리면서 영원히 블록되는 상태
- ex. 스레드 A가 자원 X를 획득하고 자원 Y를 기다리고 있고, 스레드 B가 자원 Y를 획득하고 자원 X를 기다리고 있는 상황
- 해결 방법
  - 자원 할당 순서 일관성 유지: 모든 스레드가 동일한 순서로 자원을 요청
  - 시간 제한: 자원 획득을 위한 시간 제한을 설정하여 데드락이 발생하기 전에 해제하도록 함
  - 타임아웃: 자원을 획득하지 못하면 일정 시간 후에 강제로 해제하도록 함

3. 리빙락 (Livelock)
- 두 개 이상의 스레드가 서로에게 양보하면서 계속해서 상태를 변경하지만, 실제 작업은 진행되지 않는 상태
- ex. 두 개의 스레드가 서로에게 양보하면서 무한 루프에 빠지는 상황
- 해결 방법
  - 임의의 지연: 스레드가 양보할 때 임의의 시간을 지연시켜 다른 스레드가 먼저 실행될 기회를 줌.
  - 우선순위 부여: 스레드에 우선순위를 부여하여 특정 스레드가 먼저 실행되도록 함.

4. 스타베이션 (Starvation)
- 한 스레드가 계속해서 다른 스레드에게 자원을 양보하여 영원히 실행 기회를 얻지 못하는 상태
- ex. 높은 우선순위를 가진 스레드가 계속해서 실행되어 낮은 우선순위를 가진 스레드가 실행되지 못하는 상황
- 해결 방법
  - 공정 스케줄링: 모든 스레드가 공정하게 실행 기회를 얻도록 스케줄링 알고리즘을 사용함.
  - 우선순위 조정: 필요에 따라 스레드의 우선순위를 조정함.

### 해결을 위한 일반적인 접근법
- 동기화: synchronized 키워드, Lock 인터페이스 등을 사용하여 공유 데이터에 대한 접근을 제어.
- 원자성: AtomicInteger, AtomicLong 등의 클래스를 사용하여 단일 명령어로 값을 읽고 쓰는 연산을 수행.
- 락 관리: 락을 얻고 해제하는 과정을 신중하게 관리하여 데드락을 방지.
- 스레드 풀: 스레드 생성 및 관리 오버헤드를 줄이기 위해 스레드 풀을 사용.
- 비동기 처리: Future, CompletableFuture 등을 사용하여 비동기적으로 작업을 처리하여 응답성을 높임.


## **블로킹(Blocking)과 논블로킹(Non-Blocking)**
- **스레드가 작업을 기다리는 방식**에 대한 개념
- 주로 I/O 작업(파일 읽기, 네트워크 요청)이나 동기화 관련 작업에서 자주 사용.

### **블로킹(Blocking)**
- **블로킹**은 어떤 작업이 끝날 때까지 **스레드가 멈춰서 기다리는 상태**를 의미.
- 작업이 완료되기 전까지 다른 일을 할 수 없음.
- 직관적이지만 **비효율적**일 수 있음(특히 I/O 작업 시).
- 파일 읽기/쓰기 작업, 데이터베이스 쿼리 실행, 네트워크 요청 (HTTP요청)

```java
public class BlockingExample {
    public static void main(String[] args) {
        System.out.println("Start");

        try {
            // 2초 동안 현재 스레드가 멈춤 (Blocking)
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        System.out.println("End");
    }
}
```

### **논블로킹(Non-Blocking)**
- **논블로킹**은 작업이 완료되기를 기다리지 않고, **즉시 실행을 계속 진행**하는 방식
- 결과가 준비되지 않았더라도 다른 작업을 진행할 수 있음.
- **효율적**이지만, 복잡한 논리와 설계가 필요함.
- Java에서는 java.nio(New I/O) 패키지를 사용하여 논블로킹 I/O 작업을 수행할 수 있음.
- 대규모 네크워크 서버(채팅서버, 파일 업로드서버), 비동기 이벤트 처리.
```java
import java.nio.*;
import java.nio.channels.*;
import java.io.*;
import java.nio.charset.StandardCharsets;

public class NonBlockingIOExample {
    public static void main(String[] args) throws IOException {
        RandomAccessFile file = new RandomAccessFile("example.txt", "rw");
        FileChannel channel = file.getChannel();

        // 채널을 논블로킹 모드로 설정
        channel.configureBlocking(false);

        ByteBuffer buffer = ByteBuffer.allocate(48);
        int bytesRead = channel.read(buffer);

        while (bytesRead != -1) {
            if (bytesRead == 0) {
                System.out.println("Waiting for data...");
            } else {
                System.out.println("Read " + bytesRead + " bytes");
                buffer.flip();

                while (buffer.hasRemaining()) {
                    System.out.print((char) buffer.get());
                }

                buffer.clear();
            }

            bytesRead = channel.read(buffer); // 다음 데이터를 읽음
        }

        file.close();
    }
}
```

## **싱크(Sync)와 어싱크(Async)**
- **작업의 실행 순서와 결과 처리 방식**
- 둘의 차이는 **작업이 완료되는 시점과 다른 작업과의 관계**

### **싱크(Synchronous, 동기)**
- 싱크 방식에서는 **작업이 순차적으로 실행**
- 이전 작업이 끝나야만 다음 작업이 실행되며, 작업 도중 다른 일을 하지 않음.
- **직렬 처리**: 작업이 순서대로 수행됨.
- **단순하고 직관적**: 결과를 기다린 후 바로 다음 코드를 실행.
- 작업이 길어지면 **성능 저하**: 다음 작업이 계속 대기해야 하기 때문.
- **비유 : 식당의 셀프 계산대 →** 한 명이 계산을 끝낼 때까지 다음 손님은 기다려야 함.
- 작업 순서가 중요한 경우(파일을 읽고 바로 처리함), 작업시간이 짧고 병렬 처리가 필요 없는 경우 (단순계산)

```java
public class SyncExample {
    public static void main(String[] args) {
        System.out.println("Start");

        // 동기 방식: 작업이 완료될 때까지 기다림
        String result = performTask();
        System.out.println("Task Result: " + result);

        System.out.println("End");
    }

    public static String performTask() {
        // 작업 시간이 오래 걸림
        try {
            Thread.sleep(2000); // 2초 대기
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return "Task Completed";
    }
}
```

### **어싱크(Asynchronous, 비동기)**
- 어싱크 방식에서는 **작업이 바로 완료되지 않아도, 다른 작업을 먼저 진행**
- 결과는 나중에 준비되면 처리
- **병렬 처리 가능**: 다른 작업을 멈추지 않고 실행.
- 더 **효율적**: 오래 걸리는 작업을 대기하지 않으므로 성능 향상.
- 구현이 **복잡**: 결과가 언제 도착할지 모르기 때문에 콜백, Future, Promise 등을 사용.
- **식당의 번호표 시스템**: 주문 후 번호표를 받고 기다리는 동안 다른 손님을 받을 수 있습니다. 음식이 준비되면 호출됨.
- 작업이 오래걸리고 다른 작업과 병렬로 진행해야 함(네트워크 요청, 데이터베이스 쿼리), 응답시간이 중요한 고성능 시스템(실시간 채팅 서버, 대규모 파일 업로드 시스템)

### 블로킹/논블로킹 vs. 싱크/어싱크
- 블로킹/논블로킹은 제어 흐름에 초점을 맞춘 개념. 즉, 함수 호출 시점에 제어권이 넘어가는 방식을 의미함 (OS에게 제어권이 있음.)
- 싱크/어싱크는 결과 처리에 초점을 맞춘 개념. 즉, 함수 호출 결과를 어떻게 처리하는지에 대한 방식을 의미함. 

### 조합 가능성:
- 싱크 + 블로킹: 가장 일반적인 방식으로, 함수 호출 후 결과를 받을 때까지 기다림.
  - 데이터베이스 쿼리를 실행한 경우, 쿼리 결과가 나올 때까지 프로그램이 대기
- 싱크 + 논블로킹: 호출된 함수는 작업을 완료하기 전에 제어권을 반환하지만, 호출한 함수는 결과를 직접 확인해야 함.
  - 특정 상황에서만 사용되며, 일반적으로는 어싱크 + 논블로킹 방식이 더 선호
- 어싱크 + 블로킹: 거의 사용되지 않는 조합
- 어싱크 + 논블로킹: 비동기 작업을 효율적으로 처리하는 가장 일반적인 방식.


# 동기화
- 멀티쓰레드 환경에서는 여러 쓰레드가 **공유 자원**에 접근하기 때문에, 동기화가 필요함.
    - 동기화 : 여러 스레드가 **공유 자원에 동시에 접근하지 못하도록 제어**하는 방법 → 멀티 쓰레드 환경에서 데이터 무결성을 보장함.
- 동기화 문제를 해결을 위한 것들(락킹) : synchronized 키워드, Lock 인터페이스, Atomic 클래스, volatile 키워드, Concurrent Collections
    - 락킹(Locking) : 여러 스레드가 동시에 공유 자원에 접근하여 발생할 수 있는 문제를 방지하기 위한 동기화 메커니즘

### JVM과 쓰레드의 관계
- JVM에서 동기화가 주로 필요한 영역은 힙 영역. 힙 영역은 여러 스레드가 공유하는 공간이기 때문에,여러 스레드가 동시에 같은 객체에 접근하여 데이터를 변경하려 할 때 예상치 못한 결과가 발생할 수 있음. 이러한 상황을 방지하기 위해 동기화가 필요.

### synchronized 키워드
- 특정 코드 블록이나 메소드에 한 번에 하나의 스레드만 접근하도록 보장하는 가장 기본적인 동기화 방법
- `synchronized` 키워드를 사용하여 해당 코드 블록을 감싸면, 다른 스레드가 이 블록에 들어오려면 현재 실행 중인 스레드가 블록을 빠져나올 때까지 기다려야 함.
- 단점
    - 오버헤드가 크기 때문에 너무 자주 사용하면 성능 저하를 발생 가능.
    - 데드락 가능성이 있음.

### **(1) synchronized 블록 :** 특정 블록만 동기화.

```java
class Counter {
    private int count = 0;

    public void increment() {
        synchronized (this) { // 동기화 블록
            count++;
        }
    }

    public int getCount() {
        return count;
    }
}
```

### **(2) synchronized 메서드 :** 메서드 전체를 동기화.

```java
class Counter {
    private int count = 0;

    public synchronized void increment() { // 동기화 메서드
        count++;
    }

    public synchronized int getCount() {
        return count;
    }
}
```

### Lock 인터페이스

- **java.util.concurrent.locks** 패키지에서 제공
- `synchronized` 키워드보다 더 유연하고 세밀한 동기화를 제공하는 인터페이스.

```java
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

class Counter {
    private int count = 0;
    private final Lock lock = new ReentrantLock(); // Lock 객체 생성

    public void increment() {
        lock.lock(); // Lock 획득
        try {
            count++;
        } finally {
            lock.unlock(); // Lock 해제
        }
    }

    public int getCount() {
        lock.lock();
        try {
            return count;
        } finally {
            lock.unlock();
        }
    }
}

public class LockExample {
    public static void main(String[] args) {
        Counter counter = new Counter();

        Thread t1 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) {
                counter.increment();
            }
        });

        Thread t2 = new Thread(() -> {
            for (int i = 0; i < 1000; i++) {
                counter.increment();
            }
        });

        t1.start();
        t2.start();

        try {
            t1.join();
            t2.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        System.out.println("Final Count: " + counter.getCount());
    }
}
```

### **Atomic 클래스 (java.util.concurrent.atomic)**
- 일반적인 할당연산이 아닌 비교하고 설정하는(CAS) 연산을 통해 간단한 동기화 작업을 수행하는 클래스 → 일관성 보장

### **CAS 연산의 개념**
CAS 연산은 세 가지 요소를 사용해 작업을 수행해:
1. **기대값(현재 값)**: 메모리의 현재 값.
2. **비교값(예상 값)**: 작업자가 예상한 값.
3. **새로운 값**: 변경하려는 값.

CAS는 **현재 값과 예상 값이 일치하는지 비교한 뒤**:
- **일치하면 새로운 값으로 변경.**
- **일치하지 않으면 아무 작업도 하지 않고 실패를 알림.**
- `synchronized` 키워드보다 성능이 좋고(락을 사용하지 않기 때문에 **경량화**) 사용하기 간편
- 간단한 값 증가, 감소 등의 작업에 효과적.
- 단점
    - CAS 연산이 실패할 경우 반복적으로 시도 → 경쟁 상황이 심하면 성능 저하(오버헤드).
    - 복잡한 다변수 연산에는 적합하지 않음(여러 변수 간의 일관성 보장이 어려움).

```java
import java.util.concurrent.atomic.AtomicInteger;

public class AtomicCounter {
    private AtomicInteger count = new AtomicInteger();

    public void increment() {
        count.incrementAndGet(); // 값을 1 증가시키는 원자적 연산
    }

    public int getCount() {
        return count.get();
    }
}
```
- **종류**:
    1. **AtomicInteger, AtomicLong**: 숫자 연산을 위한 클래스.
    2. **AtomicReference**: 객체 참조를 원자적으로 교체.
    3. **AtomicBoolean**: 불리언 값을 원자적으로 변경.

### **volatile (볼라타일)키워드**
- 컴파일러에게 해당 변수에 대한 최적화를 하지 말라고 지시 즉, 항상 메인 메모리에서 값을 읽고 쓰도록 함으로써, 모든 스레드가 동일한 값을 보도록 함
- **메모리 가시성:** 여러 스레드가 공유하는 변수에 대해 모든 스레드가 항상 최신의 값을 보도록 하는 것
- **컴파일러 최적화 방지:** 컴파일러가 변수에 대한 최적화를 수행하지 않도록 해서, 항상 최신 값을 읽도록 보장합니다.
- **원자성 보장 X:** 단순히 메모리 가시성만을 보장하며, 복합적인 연산에 대해서는 원자성을 보장하지 않음
- **장점:**
    - 간단한 변수의 값을 공유하는 경우에 효과적.
- **단점:**
    - 복잡한 동기화 문제를 해결하기에는 부족.
    - 원자성이 보장되지 않으므로 주의해야 함.

```java
public class VolatileExample {
    private volatile boolean running = true;

    public void stop() {
        running = false; // 다른 스레드가 이 값을 즉시 반영해서 읽을 수 있음.
    }
}

```

### **Concurrent 계열 클래스 (java.util.concurrent)**
- 자바에서 제공하는 동시성 컬렉션 및 도구 모음.
- 여러 스레드가 동시에 접근해도 안전하게 데이터를 관리할 수 있는 컬렉션 클래스
- 락을 최소화하거나, 세분화하여 동시 접근을 효율적으로 처리
- **장점:**
    - 별도의 동기화 없이 안전하게 사용할 수 있음.
    - 성능이 좋고 다양한 동시성 작업을 지원.
- **단점:**
    - 일반적인 컬렉션에 비해 기능이 제한적일 수 있음.
- **종류 및 특징**:
    1. **ConcurrentHashMap**: 스레드 안전한 해시맵.
        - **스레드 안전한 해시맵**으로, 내부적으로 **분할 락(segmented locking)**을 사용.
        - 읽기 작업은 락이 필요하지 않고, 쓰기 작업은 부분적으로 락을 걸어 성능을 최적화.
    2. **CopyOnWriteArrayList**
        - 쓰기 작업 시 배열의 복사본을 생성 → 읽기 작업과 쓰기가 동시에 가능.
        - 읽기 빈도가 높고 쓰기 빈도가 낮은 경우에 적합.
    3. **BlockingQueue**: 스레드 간의 작업 전달에 사용되는 큐.
        - 예: `ArrayBlockingQueue`, `LinkedBlockingQueue`.
    4. **BlockingQueue**:
        - **생산자-소비자 패턴**에서 사용.
        - 큐가 비어 있으면 소비자는 대기, 꽉 차 있으면 생산자는 대기.
        - 예: `ArrayBlockingQueue`, `LinkedBlockingQueue`.
    5. **CountDownLatch**, **CyclicBarrier**, **Semaphore**:
        - 스레드 간의 동기화 제어를 위한 도구.

```java
import java.util.concurrent.ConcurrentHashMap;

public class ConcurrentExample {
    private ConcurrentHashMap<String, Integer> map = new ConcurrentHashMap<>();

    public void add(String key, int value) {
        map.put(key, value); // 여러 스레드가 동시에 접근해도 안전
    }

    public int get(String key) {
        return map.getOrDefault(key, 0);
    }
}
```

### 선택 가이드
- **간단한 동기화:** `synchronized` 키워드
- **유연하고 세밀한 동기화:** `Lock` 인터페이스
- **간단한 값 증감:** `Atomic` 클래스
- **변수 값의 가시성:** `volatile` 키워드
- **동시성 컬렉션:** `Concurrent Collections`

- **성능:** `Atomic` 클래스나 `Concurrent Collections`가 일반적으로 더 빠릅니다.
- **유연성:** `Lock` 인터페이스가 가장 유연
- **간편성:** `synchronized` 키워드가 가장 간단